{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: word2number in /opt/conda/lib/python3.7/site-packages (1.1)\n"
     ]
    }
   ],
   "source": [
    "#pip install yelp\n",
    "!pip install word2number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://jovyan:***@localhost/si330\n",
      "1 rows affected.\n"
     ]
    }
   ],
   "source": [
    "!pip install word2number\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from word2number import w2n\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "\n",
    "%load_ext sql\n",
    "%sql postgresql://jovyan:si330studentuser@localhost/si330\n",
    "def read_data():\n",
    "    restaurants_df = pd.read_csv('Restaurants.csv')\n",
    "    license_df = pd.read_csv('Liquor_Licenses.csv')\n",
    "    restaurants_df.rename(columns = {'X':'Latitude', 'Y':'Longitude'}, inplace = True)\n",
    "    license_df.rename(columns = {'street_address':'Address', 'dba':'Name', 'X':'Latitude', 'Y':'Longitude'}, inplace = True)\n",
    "    return restaurants_df,license_df\n",
    "\n",
    "def cleanAndMerge(restaurants_df,license_df):\n",
    "    all_df = pd.merge(restaurants_df, license_df, how='outer', on='Address')\n",
    "    all_df = all_df.drop_duplicates(\n",
    "      subset = ['Name_x', 'Address'],\n",
    "      keep = 'last').reset_index(drop = True)\n",
    "    all_df = all_df[~all_df['Name_x'].isna()] #get rid of places that are not restaurants\n",
    "    all_df.loc[all_df['number'].isna()==True, 'Serve_Liquor'] = \"FALSE\" #create new column, number stands for liquor license number\n",
    "    all_df.loc[all_df['number'].isna()==False, 'Serve_Liquor'] = \"TRUE\"\n",
    "    all_df['Most_Recent_License_Date']=pd.to_datetime(all_df['Most_Recent_License_Date'])\n",
    "    all_df=all_df[all_df['Most_Recent_License_Date']>'2014'] #only want data from 2015 forward\n",
    "    return all_df\n",
    "\n",
    "def callapi(term):\n",
    "    url='https://api.yelp.com/v3/businesses/search'\n",
    "    apikey=\"jewuQyQCl6xfKXLDhtaFI2xD602_A4yIS37P7DnfFk5EO6JllvzFexgI1fjSTTa2WboOr58Ur7uWm8JO8lAfxemm8HAQrnrJ39Ktfn14zrBiQ_wrkqKrb2drxRhlYHYx\"\n",
    "    headers = {'Authorization': 'Bearer %s' % apikey}\n",
    "    params = {'Authorization':apikey,'term':term,'location':'Detroit'}\n",
    "    ref=requests.get(url,params=params,headers=headers)\n",
    "    return json.loads(ref.text)\n",
    "    \n",
    "def makeaddress(x): #data cleaning, matching yelp addresses, so needed to do this\n",
    "    address=x.split(' ')\n",
    "    address1=address[0]\n",
    "    address2=address[1]\n",
    "    if len(address[1])<2:\n",
    "        address2=address[2]\n",
    "    if ('Second' in address2):\n",
    "        address2='2nd'\n",
    "    if ('Third' in address2):\n",
    "        address2='3rd'\n",
    "    try:\n",
    "        address2=str(w2n.word_to_num(address2))\n",
    "    except:\n",
    "        address2=address2.upper()\n",
    "    if address1+' '+address2=='1 PARK':\n",
    "        address1='ONE'\n",
    "\n",
    "    return address1+' '+address2\n",
    "\n",
    "def splitadd(ogadd): #if there is a hyphen in the house # do this\n",
    "    split1=ogadd.split('-')\n",
    "    try:\n",
    "        firstnum=split1[0]\n",
    "        secondnum=split1[1].split(' ')[0]\n",
    "        newfirst=firstnum+' '+split1[1].split(' ')[1]\n",
    "        newsecond=firstnum[:-len(secondnum)]+secondnum+' '+split1[1].split(' ')[1]\n",
    "        return[newfirst,newsecond]\n",
    "    except:\n",
    "        return[ogadd]\n",
    "\n",
    "def sortdata(apidic,dfaddress,yelpbool=False):\n",
    "    #print('dfaddy: ',dfaddress)\n",
    "    if yelpbool: #for the test cases\n",
    "        try:\n",
    "            yelpaddress=apidic['businesses'][0]['location']['address1']\n",
    "            #print('yelpaddy: ',yelpaddress)\n",
    "        except:\n",
    "            yelpaddress=np.nan\n",
    "        if yelpaddress ==dfaddress:\n",
    "            try:\n",
    "                rating=apidic['businesses'][0]['rating']\n",
    "                #print(' found rating')\n",
    "            except:\n",
    "                rating=np.nan\n",
    "            try:\n",
    "                price=apidic['businesses'][0]['price']\n",
    "                #print(' found price')\n",
    "            except:\n",
    "                price=np.nan\n",
    "        else:\n",
    "            price,rating=np.nan,np.nan\n",
    "    else:\n",
    "        try:\n",
    "            yelpaddress=makeaddress(apidic['businesses'][0]['location']['address1'])\n",
    "        except:\n",
    "            yelpaddress=np.nan\n",
    "        #print('yelpaddy: ',yelpaddress)\n",
    "        try: #for the test cases\n",
    "            dfaddress=makeaddress(dfaddress)\n",
    "        except:\n",
    "            pass\n",
    "        if yelpaddress in dfaddress:\n",
    "            try:\n",
    "                rating=apidic['businesses'][0]['rating']\n",
    "                #print(' found rating')\n",
    "            except:\n",
    "                rating=np.nan\n",
    "            try:\n",
    "                price=apidic['businesses'][0]['price']\n",
    "                #print(' found price')\n",
    "            except:\n",
    "                price=np.nan\n",
    "        else:\n",
    "            price,rating=np.nan,np.nan\n",
    "    return(rating,price)\n",
    "def sqlmaker(row,dfrating,dfprice):\n",
    "    pdic={}\n",
    "    pdic[np.nan]=1\n",
    "    try:\n",
    "        existingprices=%sql select * from \"price\"\n",
    "        for x in existingprices:\n",
    "            pdic[x[1]]=x[0]\n",
    "        #print('tables exist')\n",
    "        clear_output()\n",
    "    except:\n",
    "        #print('dropping tables')\n",
    "        %sql drop table if exists \"price\" cascade\n",
    "        %sql drop table if exists \"restaurant\" cascade\n",
    "        %sql create table \"price\" (\"id\" int,\"price\" varchar(255),PRIMARY KEY(\"id\"))\n",
    "        %sql CREATE TABLE \"restaurant\" (\"name\" varchar(255),\"lat\" float,\"long\" float,\"address\" varchar(255),\"servesl\" bool,\"price_id\" int,\"rating\" float, PRIMARY KEY(\"name\",\"address\"),  FOREIGN KEY(\"price_id\") REFERENCES \"price\"(\"id\"));\n",
    "        nan=np.nan\n",
    "        %sql insert into \"price\" (\"id\",\"price\") values (1,:nan)\n",
    "        print('created tables')\n",
    "    name=row.loc['Name_x']\n",
    "    address=row.loc['Address']\n",
    "    lat=row.loc['Latitude_x']\n",
    "    long=row.loc['Longitude_x']\n",
    "    servesl=row.loc['Serve_Liquor']\n",
    "    try:\n",
    "        #print(dfprice)\n",
    "        np.isnan(dfprice)\n",
    "        price_id=1\n",
    "    except:     \n",
    "        if dfprice in pdic:\n",
    "            #print('old value',pdic,dfprice)\n",
    "            price_id=pdic[dfprice]\n",
    "        else:\n",
    "            #print('newvalue',dfprice)\n",
    "            price_id=len(pdic)+1\n",
    "            price=dfprice\n",
    "            %sql insert into \"price\" (\"id\",\"price\") values (:price_id,:price)\n",
    "    try: \n",
    "        %sql INSERT INTO \"restaurant\" (\"name\",\"lat\",\"long\",\"address\",\"servesl\",\"price_id\",\"rating\") VALUES (:name,:lat,:long,:address,:servesl,:price_id,:dfrating);\n",
    "    except:\n",
    "        logs.append([name,address,lat,long,price_id,dfrating])\n",
    "        \n",
    "def yelper(y):\n",
    "    dfname=y['Name_x']\n",
    "    dfaddress=makeaddress(y['Address'])\n",
    "    if '-' in dfaddress:\n",
    "        dfaddress=splitadd(dfaddress)\n",
    "    else:\n",
    "        dfaddress=[dfaddress]\n",
    "\n",
    "    yelpdic=callapi(dfname)\n",
    "    rating,price=sortdata(yelpdic,dfaddress)\n",
    "    sqlmaker(y,rating,price)\n",
    "    return rating,price\n",
    "logs=[]\n",
    "restaurants_df,license_df=read_data()\n",
    "all_df=cleanAndMerge(restaurants_df,license_df)\n",
    "# all_df=all_df\n",
    "all_df[['review','price']]=all_df.apply(yelper,axis=1).apply(pd.Series)\n",
    "all_df.to_pickle(\"./alldf.pkl\")\n",
    "#all_df=pd.read_pickle('./alldf.pkl')\n",
    "logs #prints out data that could not be put into sql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://jovyan:***@localhost/si330\n",
      "1 rows affected.\n",
      " * postgresql://jovyan:***@localhost/si330\n",
      "1 rows affected.\n",
      " * postgresql://jovyan:***@localhost/si330\n",
      "0 rows affected.\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "import pandas.api.types as ptypes\n",
    "def test_read_data():\n",
    "    assert len(read_data()) == 2\n",
    "    assert type(read_data()[0]) == pd.DataFrame\n",
    "    assert type(read_data()[1]) == pd.DataFrame\n",
    "    assert \"Latitude\" in read_data()[0]\n",
    "    assert \"Address\" in read_data()[1]\n",
    "\n",
    "def test_cleanAndMerge():\n",
    "    assert isinstance(cleanAndMerge(restaurants_df,license_df), pd.DataFrame)\n",
    "    assert ptypes.is_datetime64_any_dtype(cleanAndMerge(restaurants_df,license_df)['Most_Recent_License_Date'])\n",
    "    assert \"Serve_Liquor\" in cleanAndMerge(restaurants_df,license_df)\n",
    "\n",
    "def test_callapi():\n",
    "    assert isinstance(callapi(cleanAndMerge(restaurants_df,license_df)['Name_x'][0]), dict)\n",
    "    assert \"rating\" in callapi('The Whitney Restaurant')['businesses'][0]\n",
    "    assert \"price\" in callapi('Al Baraka Restaurant')['businesses'][0]\n",
    "    \n",
    "def test_makeaddress():\n",
    "    assert isinstance(makeaddress('4219 Woodward Ave'), str)\n",
    "    assert makeaddress('7625 Michigan Ave') == '7625 MICHIGAN'\n",
    "    assert makeaddress('1509 Second St') == '1509 2ND'\n",
    "    assert makeaddress('1 park') == 'ONE PARK'\n",
    "    \n",
    "def test_splitadd():\n",
    "    assert isinstance(splitadd('441 Grand River Ave'), list)\n",
    "    assert splitadd('125-29 Michigan Ave') == ['125 Michigan', '129 Michigan']\n",
    "    assert splitadd('2690 E Jefferson Ave') == ['2690 E Jefferson Ave']\n",
    "    assert splitadd('2727-31 Russell St') == ['2727 Russell', '2731 Russell']\n",
    "\n",
    "def test_sortdata():\n",
    "    assert sortdata(callapi('-320 Coffee & Creamery'),'474 Peterboro Street #201',False) == (4.5, '$$')\n",
    "    assert sortdata(callapi('-320 Coffee & Creamery'),'474 Peterboro Street #201',True) == (np.nan, np.nan)\n",
    "    #shows that makeaddress was necessary as Yelp could not search this address without it\n",
    "\n",
    "\n",
    "def test_sqlmaker():\n",
    "    restaurant_exist = %sql SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'restaurant')\n",
    "    price_exist = %sql SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'price')    \n",
    "    assert restaurant_exist[0][0] == True\n",
    "    assert price_exist[0][0] == True\n",
    "    len_multiple=%sql SELECT name FROM \"restaurant\" where name='Asian Corned Beef'\n",
    "    assert len(len_multiple)  !=1  #makes sure the primary key combination is working\n",
    "    \n",
    "    \n",
    "#yelper just calls all these functions so im not sure if we'll need a test_yelper?\n",
    "    \n",
    "    \n",
    "    \n",
    "test_read_data()\n",
    "test_cleanAndMerge()\n",
    "test_callapi()\n",
    "test_makeaddress()\n",
    "test_splitadd()\n",
    "test_sortdata()\n",
    "test_sqlmaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "host=\"localhost\"\n",
    "dbname=\"si330\"\n",
    "user=\"jovyan\"\n",
    "password=\"si330studentuser\"\n",
    "\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(host=host,dbname=dbname, user=user, password=password)\n",
    "cursor = conn.cursor()\n",
    "conn.autocommit=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-43197b05c598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrating1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrating2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "query1=\"\"\"select avg(rating), count(*) from restaurant where servesl='False' and rating != 'nan' GROUP BY rating order by count(*) ASC\"\"\"\n",
    "cursor.execute(query1)\n",
    "false = cursor.fetchall()\n",
    "query2=\"\"\"select avg(rating), count(*) from restaurant where servesl='True' and rating != 'nan' GROUP BY rating order by count(*) ASC\"\"\"\n",
    "cursor.execute(query2)\n",
    "true = cursor.fetchall()\n",
    "rating1, count1 = zip(*false)\n",
    "rating2, count2 = zip(*true)\n",
    "plt.bar(rating1, count1, width=0.4)\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('yelp_rating')\n",
    "plt.xlim([1, 5.5])\n",
    "plt.bar(rating2, count2, width=0.4)\n",
    "plt.title('Ratings for Detroit Restaurants')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Do Not Serve Liquor')\n",
    "orange_patch = mpatches.Patch(color='orange', label='Serve Liquor')\n",
    "plt.legend(handles=[blue_patch, orange_patch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1=\"\"\"select avg(rating) from restaurant where servesl='False' and rating != 'nan'\"\"\"\n",
    "cursor.execute(query1)\n",
    "false = cursor.fetchall()\n",
    "query2=\"\"\"select avg(rating) from restaurant where servesl='True' and rating != 'nan'\"\"\"\n",
    "cursor.execute(query2)\n",
    "true = cursor.fetchall()\n",
    "rating1 = false[0][0]\n",
    "rating2 = true[0][0]\n",
    "plt.ylabel('average_yelp_rating')\n",
    "plt.xlabel('restaurants')\n",
    "plt.title('Ratings for Detroit Restaurants')\n",
    "plt.bar('Do Not Serve Liquor', rating1, width=0.3)\n",
    "plt.bar('Serve Liquor', rating2, width=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statisticalTesting():\n",
    "    from scipy import stats\n",
    "    import seaborn as sns\n",
    "    df_alc= %sql select rating from \"restaurant\" where servesl=True and rating !='nan';\n",
    "    df_nonalc = %sql select rating from \"restaurant\" where servesl=False and rating !='nan';\n",
    "    stats.levene(df_alc.DataFrame()['rating'],df_nonalc.DataFrame()['rating'])\n",
    "    #small p value says they do not have equal variances, thus use equal_var=False\n",
    "    \n",
    "    %sql select servesl, avg(rating) from \"restaurant\" where servesl=True and rating !='nan' group by servesl;\n",
    "    #gets mean value ^\n",
    "    sns.displot(data=df_alc.DataFrame(), x=\"rating\") #looks normal, slightly skewed but unimodal\n",
    "    stats.shapiro(df_alc.DataFrame()['rating']) # this test shows relative nonnormality\n",
    "    len(df_alc) #but because the sample size is so great we can assume normality\n",
    "    \n",
    "    %sql select servesl, avg(rating) from \"restaurant\" where servesl=False and rating !='nan' group by servesl; \n",
    "    #gets mean value ^\n",
    "    sns.displot(data=df_nonalc.DataFrame(), x=\"rating\") #plot them, looks relativly normal and unimodal\n",
    "    stats.shapiro(df_nonalc.DataFrame()['rating']) #this test checks for normality, and the results are that our data are nonnormal\n",
    "    len(df_nonalc) #but because the sample size is so great we can assume normality\n",
    "    \n",
    "    pvalue=stats.ttest_ind(df_alc.DataFrame()['rating'],df_nonalc.DataFrame()['rating'],equal_var=False)[1]\n",
    "    return pvalue\n",
    "statisticalTesting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"ranalysis.png\" width=\"600\" height=\"400\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did both a two sided test and a one sided test. cannot doa one sided test in python for some reason so put the data into r and did a one sided welch test there. results can be seen above. Both are statistically significant, so the results are statistically significant at the .05% level. The means are  different, and the mean of restaurants that dont serve alcohol is  less than the mean rating of restaurants that do serve alcohol at the .05% significance level. This is an interesting result. Also of interest. The R statistical one sided test P=value was exactly half of the value returned by python. Previously in a homework, we were told you could not change the test from two-sided to one sided like this, but it worked in this senario. The accuracy was to the millionths place (rounded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
